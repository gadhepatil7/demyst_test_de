{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "235eb552-4c8f-43c3-bf18-59f9075bf22c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+-------------+\n| id|first_name| last_name|             address|date_of_birth|\n+---+----------+----------+--------------------+-------------+\n|  0|dBYjDGoILL|dBYjDGoILL|ZqlMtQOHpFYYWAettINf|   1993-02-22|\n|  1|Weyeqbrpja|Weyeqbrpja|UhOdwBAqAIvkZKPKoafd|   1973-05-14|\n|  2|vTsnFQrmQt|vTsnFQrmQt|lgLUnlqlIaDyXEOSntQf|   1961-07-03|\n|  3|gPHMQOdZMC|gPHMQOdZMC|MASxhpInmJkaOBCCPdXA|   1966-01-22|\n|  4|PXLDHXcQGW|PXLDHXcQGW|auCwYcfpfYBTLGKcjysI|   1990-07-28|\n|  5|CqhwKsnlbV|CqhwKsnlbV|oahoYjbVkafrhLuwoAHe|   1972-09-13|\n|  6|IxPQnXzlon|IxPQnXzlon|bcFYrmetqptkfdEqJpmf|   1968-07-16|\n|  7|jhIzSNZcFG|jhIzSNZcFG|kSiYABGkOYvWPbAqzTsB|   1986-04-10|\n|  8|rOTyzEHqsQ|rOTyzEHqsQ|NgmxiSSqnlCOavBmebrv|   1973-01-30|\n|  9|JlzGShLXCV|JlzGShLXCV|YkdupFBHbdagGRCOIKwL|   1976-11-02|\n+---+----------+----------+--------------------+-------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, udf\n",
    "from pyspark.sql.types import StringType, DateType\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Generate Large CSV\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "def generate_random_string(length=8):\n",
    "    return ''.join(random.choices(string.ascii_letters, k=length))\n",
    "\n",
    "def generate_random_date(start_year=1950, end_year=2000):\n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date = datetime(end_year, 12, 31)\n",
    "    random_date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
    "    return random_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Register UDFs\n",
    "random_string_udf = udf(generate_random_string, StringType())\n",
    "random_date_udf = udf(generate_random_date, StringType())\n",
    "\n",
    "# Generate a DataFrame with random data\n",
    "num_records = 1000000  # Adjust the number for larger files\n",
    "df = spark.range(num_records) \\\n",
    "    .withColumn(\"first_name\", random_string_udf(lit(10))) \\\n",
    "    .withColumn(\"last_name\", random_string_udf(lit(10))) \\\n",
    "    .withColumn(\"address\", random_string_udf(lit(20))) \\\n",
    "    .withColumn(\"date_of_birth\", random_date_udf(lit(1950), lit(2000)))\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.write.csv(\"large_dataset_spark_3.csv\", header=True)\n",
    "df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5baa7833-5ebc-48fc-aa17-f098a32ea098",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+-------------+\n| id|first_name| last_name|             address|date_of_birth|\n+---+----------+----------+--------------------+-------------+\n|  0|mnlfJgnpQR|mnlfJgnpQR|nNqvuqeJQgsJdHNIlJkR|   1998-07-27|\n|  1|UFuRByqRCf|UFuRByqRCf|xSCbOtEUgkmWpCgWKdGC|   2000-04-06|\n|  2|FABIXDNUsm|FABIXDNUsm|KTtgHBsHzALAeSwNAFbB|   1998-01-15|\n|  3|pRZnuugaVb|pRZnuugaVb|fxEVMuhnypbxnkooioPW|   1994-10-29|\n|  4|myhXQuSVmO|myhXQuSVmO|DtkGclMLPhrEDNhXtfXa|   1999-05-27|\n|  5|bEQPMkGewD|bEQPMkGewD|cjZwQjXYIVGzuUviScwb|   1971-11-15|\n|  6|VnZXaKzwzt|VnZXaKzwzt|GkRxWEqaWfLJLjRmGCjd|   1982-05-30|\n|  7|qduHvUrUsY|qduHvUrUsY|XcIyvOQkARkeoLAwewDe|   1994-05-15|\n|  8|BXtpkPDOzC|BXtpkPDOzC|ykOSWobzsZNSeovweylc|   1970-08-12|\n|  9|HVCYCobMBt|HVCYCobMBt|kLiCWfMJWwPQvvSTGdnz|   1993-05-24|\n+---+----------+----------+--------------------+-------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Define UDFs for anonymization\n",
    "def anonymize_string(length=8):\n",
    "    return ''.join(random.choices(string.ascii_letters, k=length))\n",
    "\n",
    "anonymize_string_udf = udf(anonymize_string, StringType())\n",
    "\n",
    "# Apply anonymization\n",
    "anonymized_df = df.withColumn(\"first_name\", anonymize_string_udf(lit(10))) \\\n",
    "                  .withColumn(\"last_name\", anonymize_string_udf(lit(10))) \\\n",
    "                  .withColumn(\"address\", anonymize_string_udf(lit(20)))\n",
    "\n",
    "# Save the anonymized DataFrame to a new CSV file\n",
    "anonymized_df.write.csv(\"anonymized_large_dataset_spark_2.csv\", header=True)\n",
    "\n",
    "anonymized_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b641ebd-383e-4dc4-9840-8629fb8eeb89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2024-08-12 12:27:51",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
